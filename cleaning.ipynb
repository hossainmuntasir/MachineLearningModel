{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameImporter:\n",
    "    \"\"\"\n",
    "    Imports files in a directory and concats to a single dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, path=None):\n",
    "        self._df = self.search_directory(path)\n",
    "        \n",
    "    @property\n",
    "    def df(self):\n",
    "        return self._df\n",
    "    @df.setter\n",
    "    def df(self, value):\n",
    "        self._df = value\n",
    "        \n",
    "    @staticmethod\n",
    "    def search_directory(path=None):\n",
    "        if path is not None:\n",
    "            building_dfs = []\n",
    "            for file in os.listdir(path):\n",
    "                if file.endswith('xlsx'):\n",
    "                    df = pd.read_excel(os.path.join(path, file), \n",
    "                                    na_values='-', \n",
    "                                    parse_dates=['Time'], \n",
    "                                    date_format='%Y-%m-%d %H:%M:%S')\n",
    "                    building_dfs.append(df)\n",
    "            return pd.concat(building_dfs)\n",
    "        raise ValueError(f'Incorrect path. \\tPath: {path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListSplitter:\n",
    "    \"\"\"\n",
    "    Iterates through a list of integers. If difference between an integer and the next\n",
    "    is more than 1, it will split the list.\n",
    "    \n",
    "    Returns a list of all split lists\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def split_list_on_increment(lst):\n",
    "        # get list of indices, if values in list increment by more than 1 split list\n",
    "        sublists = []\n",
    "        sublist = []\n",
    "        for i in range(len(lst)):\n",
    "            if i == 0 or lst[i] - lst[i-1] <= 1:\n",
    "                sublist.append(lst[i])\n",
    "            else:\n",
    "                sublists.append(sublist)\n",
    "                sublist = [lst[i]]\n",
    "        sublists.append(sublist)\n",
    "        # return all split lists (intervals)\n",
    "        return sublists      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameCleaner:\n",
    "    \"\"\"\n",
    "    Implements basic cleaning functions to a DataFrame\n",
    "    \n",
    "    Can use an existing dataframe object, or import from path directory using DataFrame importer\n",
    "    \n",
    "    Specify building_no at instantiation as well\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df=None, path=None, building_no=None):\n",
    "        if (df):\n",
    "            self._df = df.sort_values()\n",
    "        elif (path):\n",
    "            self._df = DataFrameImporter(path).df\n",
    "        else:\n",
    "            raise ValueError(\"'df' or 'path' need to be specified\")\n",
    "        \n",
    "        self.remap_columns()\n",
    "        self.adjust_index()\n",
    "        self.set_dtypes()\n",
    "        self.add_time_columns()\n",
    "        self.add_temp_columns()\n",
    "        self.add_cumsum_columns()\n",
    "        self.df['building_no'] = building_no\n",
    "        \n",
    "    @property\n",
    "    def df(self):\n",
    "        return self._df\n",
    "    @df.setter\n",
    "    def df(self, value):\n",
    "        self._df = value\n",
    "        \n",
    "    def drop_dupplicates(self):\n",
    "        self.df = self.df.drop_duplicates()\n",
    "        \n",
    "    def remap_columns(self):\n",
    "        columns_map = {'Zone name':'Zone_name',\n",
    "                    'Time':'Datetime',\n",
    "                    'Zone temperature (degree Celsius)':'Zone_temp',\n",
    "                    'Slab temperature (degree Celsius)': 'Slab_temp',\n",
    "                    'Dew point temperature (degree Celsius)':'Dew_temp',\n",
    "                    'Outside air temperature (degree Celsius)':'Ambient_temp',\n",
    "                    'Damper status (%)':'Damper_status',\n",
    "                    'Damper status':'Damper_status',\n",
    "                    'Fan status':'Fan_status',\n",
    "                    'Zone CO2 (ppm)':'Zone_c02',\n",
    "                    'Louver status':'Louver_status'}\n",
    "        self.df = self._df.rename(columns=columns_map)\n",
    "    \n",
    "    def adjust_index(self):\n",
    "        self.df = self._df.sort_values(['Zone_name','Datetime']).reset_index(drop=True)\n",
    "\n",
    "    def set_dtypes(self):\n",
    "        dtypes_map = {'Zone_name':'object',\n",
    "                    'Datetime':'datetime64[ns]',\n",
    "                    'Zone_temp':float,\n",
    "                    'Slab_temp':float,\n",
    "                    'Dew_temp':float,\n",
    "                    'Ambient_temp':float,\n",
    "                    'Damper_status':float,\n",
    "                    'Fan_status':'object',\n",
    "                    'Zone_c02':float,\n",
    "                    'Louver_status':'object'}\n",
    "        \n",
    "        for k,v in dtypes_map.items():\n",
    "            if k in self.df.columns:\n",
    "                self.df[k] = self.df[k].astype(v)\n",
    "                \n",
    "    def add_time_columns(self):\n",
    "        # calc time between records\n",
    "        self.df['Datetime_diff_mins'] = np.nan\n",
    "        for (_, temp) in self.df.groupby(['Zone_name']):\n",
    "            self.df.loc[temp.index,'Datetime_diff_mins'] = (temp.Datetime.diff()).dt.total_seconds() // 60\n",
    "\n",
    "        self.df['Date'] = self.df.Datetime.dt.date\n",
    "        self.df['Time'] = self.df.Datetime.dt.time\n",
    "        self.df['Year'] = self.df.Datetime.dt.year\n",
    "        self.df['Month'] = self.df.Datetime.dt.month\n",
    "        self.df['Day'] = self.df.Datetime.dt.day\n",
    "        self.df['DOW'] = self.df.Datetime.dt.dayofweek\n",
    "        \n",
    "        season_map = {12:1,1:1,2:1,3:2,4:2,5:2,6:3,7:3,8:3,9:4,10:4,11:4}\n",
    "        self.df['Season'] = self.df.Month.map(season_map)\n",
    "        \n",
    "\n",
    "    def add_temp_columns(self):\n",
    "        self.df['Zone_temp_diff'] = np.nan\n",
    "        self.df['Slab_temp_diff'] = np.nan\n",
    "        self.df['Dew_temp_diff'] = np.nan\n",
    "        self.df['Ambient_temp_diff'] = np.nan\n",
    "        \n",
    "        for (_, temp) in self.df.groupby(['Zone_name']):\n",
    "            self.df.loc[temp.index,'Zone_temp_diff'] = temp.Zone_temp.diff()\n",
    "            self.df.loc[temp.index,'Slab_temp_diff'] = temp.Slab_temp.diff()\n",
    "            self.df.loc[temp.index,'Dew_temp_diff'] = temp.Dew_temp.diff()\n",
    "            self.df.loc[temp.index,'Ambient_temp_diff'] = temp.Ambient_temp.diff()\n",
    "        \n",
    "        \n",
    "    def add_cumsum_columns(self):     \n",
    "        # Fan status\n",
    "        self.df['Cumulative_fan_on_mins'] = np.nan\n",
    "        # self.df['Cumulative_fan_off_mins'] = np.nan\n",
    "        self.df['Fan_on_group'] = np.nan\n",
    "        \n",
    "        # Damper status (0 to 100)\n",
    "        if 'Damper_satus' in self.df.columns:\n",
    "            self.df['Cumulative_damper_open_mins'] = np.nan\n",
    "            self.df['Damper_open_group'] = np.nan\n",
    "            \n",
    "        # Louver = Close/Open\n",
    "        if 'Louver_status' in self.df.columns:\n",
    "            self.df['Cumulative_louver_open_mins'] = np.nan\n",
    "            self.df['Louver_open_group'] = np.nan\n",
    "        \n",
    "        \n",
    "        for (_, temp) in self.df.groupby(['Zone_name']):\n",
    "            # calc cumulative time fan is on for each interval\n",
    "            on_indices = ListSplitter.split_list_on_increment(temp[temp.Fan_status=='On'].index)\n",
    "            for i, intervals in enumerate(on_indices):\n",
    "                self.df.loc[intervals,'Cumulative_fan_on_mins'] = ((self.df.loc[intervals,'Datetime'].diff()).dt.total_seconds() // 60).cumsum()\n",
    "                self.df.loc[intervals,'Fan_on_group'] = i+1\n",
    "                \n",
    "            # # calc cumulative time fan is off for each interval\n",
    "            # off_indices = split_list_on_increment(temp[temp.Fan_status=='Off'].index)\n",
    "            # for intervals in off_indices:\n",
    "            #     self.df.loc[intervals,'Cumulative_fan_off_mins'] = ((self.df.loc[intervals,'Datetime'].diff()).dt.total_seconds() // 60).cumsum()\n",
    "            \n",
    "            if 'Damper_status' in self.df.columns:\n",
    "                open_indices = ListSplitter.split_list_on_increment(temp[temp.Damper_status==100].index)\n",
    "                for i, intervals in enumerate(open_indices):\n",
    "                    self.df.loc[intervals,'Cumulative_damper_open_mins'] = ((self.df.loc[intervals,'Datetime'].diff()).dt.total_seconds() // 60).cumsum()\n",
    "                    self.df.loc[intervals,'Damper_open_group'] = i+1\n",
    "            \n",
    "            if 'Louver_status' in self.df.columns:                  \n",
    "                open_indices = ListSplitter.split_list_on_increment(temp[temp.Louver_status=='Open'].index)\n",
    "                for i, intervals in enumerate(open_indices):\n",
    "                    self.df.loc[intervals,'Cumulative_louver_open_mins'] = ((self.df.loc[intervals,'Datetime'].diff()).dt.total_seconds() // 60).cumsum()\n",
    "                    self.df.loc[intervals,'Louver_open_group'] = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For all Validation Checks: </br><b>Return True if FAULTY/INVALID</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp:\n",
    "# Faulty if any of the following are true:\n",
    "    # Sudden drop in temp (typically to 0 or -1)\n",
    "    # Value is out of range\n",
    "    # Constant value for 24hrs+                   \n",
    "class TemperatureValidation:\n",
    "    \"\"\"\n",
    "    Class containing all temperature validation checks, works by specifying an area.\n",
    "    \n",
    "    eg area='Zone' will do all temperature validation checks for Zone_temp column\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self._df = df\n",
    "        \n",
    "    @property\n",
    "    def df(self):\n",
    "        return self._df\n",
    "    \n",
    "    def check_invalid_temperature_range(self, area, min=-5, max=50):\n",
    "        # Return bool series of values that are not within valid temperature range\n",
    "        return ~((self.df[f'{area}_temp'] > min) & (self.df[f'{area}_temp'] < max))\n",
    "    \n",
    "    def check_suboptimal_temperature_range(self, area, min=20, max=24):\n",
    "        # Return bool series of values that are not within optimal temperature range\n",
    "        return ~((self.df[f'{area}_temp'] > min) & (self.df[f'{area}_temp'] < max))\n",
    "         \n",
    "    def check_sudden_change(self, area, drop=15):\n",
    "        # Return bool series of values that have not changed it in temp minimally\n",
    "        return ~(abs(self.df[f'{area}_temp_diff']) < drop)\n",
    "    \n",
    "    def check_for_constant(self, area, hours=24):\n",
    "        # Create bool series, set values to false\n",
    "        temp_series = pd.Series([False for _ in range(len(self.df))], index=self.df.index)\n",
    "        for (_, df) in self.df.groupby(['Zone_name']):\n",
    "            constant_indices = ListSplitter.split_list_on_increment(df[df[f'{area}_temp_diff']==0].index)\n",
    "            for indices in constant_indices:\n",
    "                if len(indices)>1:\n",
    "                    # total time = most recent time minus oldest time\n",
    "                    total_time = (df.at[indices[-1],'Datetime'] - df.at[indices[0],'Datetime']).total_seconds() / 3600\n",
    "                    if total_time >= hours:\n",
    "                        # if total time is more than 24 hrs update all rows in between to True (invalid)\n",
    "                        temp_series.loc[indices] = True\n",
    "        return temp_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zone co2:\n",
    "    # Faulty if > 800ppm\n",
    "class C02Validation:\n",
    "    \"\"\"\n",
    "    Class containing C02 validation checks\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self._df = df\n",
    "        \n",
    "    @property\n",
    "    def df(self):\n",
    "        return self._df\n",
    "        \n",
    "    def check_invalid_ppm(self, max_ppm=800):\n",
    "        return self.df.Zone_c02 > max_ppm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OperatingHours:\n",
    "    \"\"\"\n",
    "    Class containing building hour information\n",
    "    \n",
    "    Must set building_no when instantiating, can also optionally set amount of hours\n",
    "    prior to open is the optimum start time for each building. default is 2\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, building_no, optimum=2):\n",
    "        self._df_oh = self.get_operating_hours(building_no, optimum)\n",
    "        \n",
    "    @property\n",
    "    def df_oh(self):\n",
    "        return self._df_oh\n",
    "            \n",
    "    @staticmethod\n",
    "    def get_operating_hours(building_no, optimum):\n",
    "        match building_no:\n",
    "            case 1:\n",
    "                oh_dict = {'open':[8,8,7,8,8,10,12], 'close':[21,21,21,21,21,17,17]}\n",
    "            case 2:\n",
    "                oh_dict = {'open':[8,8,8,8,8,8,8], 'close':[17,17,17,17,17,17,17]}\n",
    "            case 3:\n",
    "                oh_dict = {'open':[8,8,7,8,8,10,12], 'close':[18,18,18,18,18,18,18]}\n",
    "            case _:\n",
    "                print('Invalid building.\\t Value: {building_no}')\n",
    "                \n",
    "        oh_dict['open'] = [datetime.time(hour) for hour in oh_dict['open']]\n",
    "        oh_dict['close'] = [datetime.time(hour) for hour in oh_dict['close']]\n",
    "        \n",
    "        df = pd.DataFrame(oh_dict, index=[i for i in range (7)])\n",
    "        df['optimum'] = (df.open.apply(lambda x: pd.to_datetime(x.strftime('%H:%M:%S'))) - datetime.timedelta(hours=optimum)).dt.time\n",
    "        \n",
    "        return df[['optimum','open','close']]\n",
    "    \n",
    "# Fan status:\n",
    "# Faulty if:\n",
    "    # Fan running anytime outside of operating hours, until optimum start time of building\n",
    "    # Running when zone temp is within ideal range (20 to 24)\n",
    "    # Running during occupied hrs when ambient temp < 18 or greater than 23 and zone co2 < 800 ppm and damper is fully open\n",
    "class FanValidation:\n",
    "    \"\"\"\n",
    "    Class containing fan validations\n",
    "    \n",
    "    Instantiate by specying building_no along with dataframe object\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df, building_no=None):\n",
    "        if not (building_no):\n",
    "            raise ValueError('building_no needs to be specified')\n",
    "        self._df = df\n",
    "        self._df_oh = OperatingHours(building_no).df_oh\n",
    "        \n",
    "    @property\n",
    "    def df(self):\n",
    "        return self._df\n",
    "    \n",
    "    @property\n",
    "    def df_oh(self):\n",
    "        return self._df_oh\n",
    "    \n",
    "    def check_fan_on_outside_oh(self, open_time='optimum'):\n",
    "        # Get bool series of fan being on outside of operating hours up to open time (default=optimum)\n",
    "        temp_series = pd.Series([False for _ in range(len(self.df))], index=self.df.index)\n",
    "        \n",
    "        # For each day of the week, check valid open and closing times\n",
    "        for (_, df) in self.df[self.df.Fan_status=='On'].groupby('DOW'):\n",
    "            # Get indices of when fan was on during closed hours\n",
    "            indices = df[(df.Time>self.df_oh.at[df.DOW.unique()[0], 'close']) |\\\n",
    "                         (df.Time<self.df_oh.at[df.DOW.unique()[0], open_time])].index\n",
    "            # Update bool series\n",
    "            temp_series.loc[indices] = True\n",
    "        return temp_series\n",
    "    \n",
    "    def check_fan_on_in_ideal_range(self, min=20, max=24):      \n",
    "        # Get bool series of all fan on in ideal temp range\n",
    "        return (self.df.Zone_temp>min)&(self.df.Zone_temp<max)&(self.df.Fan_status=='On')\n",
    "    \n",
    "    def check_fan_on_occupied_c02(self):\n",
    "        # Get bool series where fan was on during occupied hours\n",
    "        fan_on_during_occupied = pd.Series([False for _ in range(len(self.df))], index=self.df.index)\n",
    "        for (_, df) in self.df[self.df.Fan_status=='On'].groupby('DOW'):\n",
    "            indices = df[(df.Time<self.df_oh.at[df.DOW.unique()[0], 'close']) &\\\n",
    "                         (df.Time>self.df_oh.at[df.DOW.unique()[0], 'open'])].index\n",
    "            fan_on_during_occupied.loc[indices] = True\n",
    "            \n",
    "        # Get bool series where temps were < 18 or > 23\n",
    "        not_in_ideal_temperature_range = TemperatureValidation(self.df).check_suboptimal_temperature_range('Ambient', min=18, max=23)\n",
    "        \n",
    "        # Get bool series where co2 levels were < 800 ppm\n",
    "        co2_levels_valid = ~C02Validation(self.df).check_invalid_ppm()\n",
    "        \n",
    "        # Get bool series where damper was fully open\n",
    "        damper_fully_open = (self.df.Damper_status==100)\n",
    "        \n",
    "        # Return bool series of all conditions being met or not\n",
    "        return (fan_on_during_occupied & not_in_ideal_temperature_range & co2_levels_valid & damper_fully_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OscillationCounts:\n",
    "    def count_oscillations_in_window(float_values):\n",
    "        # Drop consecutive duplicates\n",
    "        float_values = float_values.loc[float_values.shift() != float_values]\n",
    "        \n",
    "        # Identify transitions\n",
    "        transitions = ((float_values.shift() == 0) & (float_values == 1)) | \\\n",
    "                    ((float_values.shift() == 1) & (float_values == 0))\n",
    "        \n",
    "        # Count transitions\n",
    "        return transitions.sum()\n",
    "\n",
    "class DamperValidation:\n",
    "    \"\"\"\n",
    "    V1 Ccomplete\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df, building_no=None):\n",
    "        if not (building_no):\n",
    "            raise ValueError('building_no needs to be specified')\n",
    "        self._df = df\n",
    "        self._df_oh = OperatingHours(building_no).df_oh\n",
    "        \n",
    "    @property\n",
    "    def df(self):\n",
    "        return self._df\n",
    "    \n",
    "    @property\n",
    "    def df_oh(self):\n",
    "        return self._df_oh\n",
    "    \n",
    "    def check_damper_open_for_too_long(self, hours=24):\n",
    "        damper_open_groups = self.df[self.df.Cumulative_damper_open_mins/60 >= hours].Damper_open_group.unique()\n",
    "        return (self.df.Damper_open_group.isin(damper_open_groups))\n",
    "    \n",
    "    def check_damper_oscillation(self, window='6H', oscillations=6):\n",
    "        # get minimum info necessary for finding invalid rows\n",
    "        df_temp = self.df[['Datetime','Zone_name','Damper_status']]\n",
    "        \n",
    "        # create a boolean column setting to default value\n",
    "        df_temp.insert(0,'Invalid', [False for _ in range(len(df_temp))])\n",
    "        \n",
    "        # iterate through each zone\n",
    "        for (zone, df) in self.df.groupby('Zone_name'):\n",
    "            \n",
    "            temp = df[['Datetime','Damper_status']]\n",
    "            \n",
    "            temp = temp.set_index('Datetime').resample('10T').first().ffill()\n",
    "            \n",
    "            # Use a rolling window to apply the oscillation counting function\n",
    "            temp['oscillations'] = temp['Damper_status'].rolling(window=window)\\\n",
    "                                .apply(OscillationCounts.count_oscillations_in_window, raw=False)\n",
    "                                \n",
    "            temp = temp.reset_index()\n",
    "\n",
    "            sublists = ListSplitter.split_list_on_increment(temp[temp.oscillations>=oscillations].index)\n",
    "            \n",
    "            for sub in sublists:\n",
    "                if (sub):\n",
    "                    min_date = temp.loc[sub[0],'Datetime']\n",
    "                    max_date = temp.loc[sub[-1],'Datetime']\n",
    "                    df_temp.loc[(df_temp.Datetime>=min_date)&(df_temp.Datetime<=max_date)&(df_temp.Zone_name==zone),'Invalid'] = True\n",
    "                    \n",
    "        return df_temp.Invalid\n",
    "            \n",
    "                           \n",
    "    \n",
    "    \n",
    "class LouverValidation:\n",
    "    \"\"\"\n",
    "    V1 Complete\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df, building_no=None):\n",
    "        if not (building_no):\n",
    "            raise ValueError('building_no needs to be specified')\n",
    "        self._df = df\n",
    "        self._df_oh = OperatingHours(building_no).df_oh\n",
    "        \n",
    "    @property\n",
    "    def df(self):\n",
    "        return self._df\n",
    "    \n",
    "    @property\n",
    "    def df_oh(self):\n",
    "        return self._df_oh\n",
    "        \n",
    "    def check_louver_open_for_too_long(self, hours=24):\n",
    "        louver_open_groups = self.df[self.df.Cumulative_louver_open_mins/60 >= hours].Damper_open_group.unique()\n",
    "        return (self.df.Louver_open_group.isin(louver_open_groups))\n",
    "\n",
    "    def check_louver_oscillation(self, window='6H', oscillations=6):\n",
    "        # get minimum info necessary for finding invalid rows\n",
    "        df_temp = self.df[['Datetime','Zone_name','Louver_status']]\n",
    "        \n",
    "        # create a boolean column setting to default value\n",
    "        df_temp.insert(0,'Invalid', [False for _ in range(len(df_temp))])\n",
    "        \n",
    "        # iterate through each zone\n",
    "        for (zone, df) in self.df.groupby('Zone_name'):\n",
    "            \n",
    "            temp = df[['Datetime','Damper_status','Louver_status']]\n",
    "            temp.loc[:,'Louver_status'] = temp.Louver_status.apply(lambda x: 0 if x=='Close' else 1 if x=='Open' else np.nan).astype(float)\n",
    "            \n",
    "            temp = temp.set_index('Datetime').resample('10T').first().ffill()\n",
    "            \n",
    "            # Use a rolling window to apply the oscillation counting function\n",
    "            temp['oscillations'] = temp['Louver_status'].rolling(window=window)\\\n",
    "                                .apply(OscillationCounts.count_oscillations_in_window, raw=False)\n",
    "                                \n",
    "            temp = temp.reset_index()\n",
    "\n",
    "            sublists = ListSplitter.split_list_on_increment(temp[temp.oscillations>=oscillations].index)\n",
    "            \n",
    "            for sub in sublists:\n",
    "                if (sub):\n",
    "                    min_date = temp.loc[sub[0],'Datetime']\n",
    "                    max_date = temp.loc[sub[-1],'Datetime']\n",
    "                    df_temp.loc[(df_temp.Datetime>=min_date)&(df_temp.Datetime<=max_date)&(df_temp.Zone_name==zone),'Invalid'] = True\n",
    "                    \n",
    "        return df_temp.Invalid\n",
    "\n",
    "    \n",
    "    def check_louver_closed_occupied_valid_temp(self):\n",
    "        # merge dataset with operating hours\n",
    "        temp = self.df.merge(self.df_oh.reset_index().rename(columns={'index':'DOW'}), on='DOW')\n",
    "        \n",
    "        # conditions needed to find rows where louver is closed during operating hours\n",
    "        cond1 = (temp.Louver_status=='Close')\n",
    "        cond2 = ((temp.Datetime.dt.time>=temp.open)&(temp.Datetime.dt.time<temp.close))\n",
    "        \n",
    "        # conditions needed to find rows where ambient temp is between 18 and 23 degrees\n",
    "        cond3 = ((temp.Ambient_temp>=18)&(temp.Ambient_temp<23))\n",
    "        \n",
    "        # conditions needed to find rows where dew point is below 19 degrees\n",
    "        cond4 = (temp.Dew_temp<19)\n",
    "        \n",
    "        return (cond1&cond2&cond3&cond4)\n",
    "    \n",
    "    def check_louver_closed_occupied_diff_temps(self):\n",
    "        # merge dataset with operating hours\n",
    "        temp = self.df.merge(self.df_oh.reset_index().rename(columns={'index':'DOW'}), on='DOW')\n",
    "        \n",
    "        # conditions needed to find rows where louver is closed outside operating hours\n",
    "        cond1 = (temp.Louver_status=='Close')\n",
    "        cond2 = ((temp.Datetime.dt.time<temp.open)|(temp.Datetime.dt.time>=temp.close))\n",
    "        \n",
    "        # diff between ambient temp and zone temp greater than or equal to 3\n",
    "        cond3 = ((temp.Ambient_temp-temp.Zone_temp).abs()>=3)\n",
    "        \n",
    "        # dew temp is less than 19\n",
    "        cond4 = (temp.Dew_temp<19)\n",
    "        \n",
    "        return (cond1&cond2&cond3&cond4)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bringing all Validation Checks into a single class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationHandler:\n",
    "    def __init__(self, df):\n",
    "        all_series = []\n",
    "        building_no = df.building_no.unique()[0]\n",
    "        \n",
    "        print(f'Building {building_no} validations started')\n",
    "        \n",
    "        valid_fan = FanValidation(df, building_no)\n",
    "        all_series.append(valid_fan.check_fan_on_in_ideal_range())\n",
    "        all_series.append(valid_fan.check_fan_on_outside_oh())\n",
    "        \n",
    "        if 'Zone_c02' in df.columns:\n",
    "            valid_c02 = C02Validation(df)\n",
    "            all_series.append(valid_c02.check_invalid_ppm())\n",
    "            \n",
    "            if 'Damper_status' in df.columns:\n",
    "                all_series.append(valid_fan.check_fan_on_occupied_c02())\n",
    "            else:\n",
    "                print('Fan Validation skipped: check_fan_on_occupied_c02')\n",
    "        else:\n",
    "            print('C02 Validations skipped')\n",
    "        \n",
    "        valid_temp = TemperatureValidation(df)\n",
    "        temp_keywords = ['Zone','Dew','Ambient','Slab']\n",
    "        temp_functions = [valid_temp.check_for_constant, valid_temp.check_invalid_temperature_range, valid_temp.check_sudden_change]\n",
    "        for word in temp_keywords:\n",
    "            for function in temp_functions:\n",
    "                all_series.append(function(word))\n",
    "                \n",
    "        if 'Damper_status' in df.columns:\n",
    "            valid_damper = DamperValidation(df, building_no)\n",
    "            all_series.append(valid_damper.check_damper_open_for_too_long())\n",
    "            all_series.append(valid_damper.check_damper_oscillation())\n",
    "        else:\n",
    "            print('Damper status validations skipped')\n",
    "            \n",
    "        if 'Louver_status' in df.columns:\n",
    "            valid_louver = LouverValidation(df, building_no)\n",
    "            all_series.append(valid_louver.check_louver_open_for_too_long())\n",
    "            all_series.append(valid_louver.check_louver_oscillation())\n",
    "            all_series.append(valid_louver.check_louver_closed_occupied_valid_temp())\n",
    "            all_series.append(valid_louver.check_louver_closed_occupied_diff_temps())\n",
    "        else:\n",
    "            print('Louver status validations skipped')\n",
    "        \n",
    "        valid_set = set()\n",
    "        for series in all_series:\n",
    "            temp_series = series[series].index\n",
    "            if isinstance(temp_series, pd.RangeIndex):\n",
    "                valid_set.update(temp_series.tolist())  # Convert RangeIndex to list before adding to set\n",
    "        else:\n",
    "            valid_set.update(temp_series)\n",
    "        \n",
    "        self._df = df.drop(valid_set).dropna(subset=['Fan_status'])\n",
    "        \n",
    "        print(f'Building {building_no} validations complete')\n",
    "        \n",
    "    @property\n",
    "    def df(self):\n",
    "        return self._df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Concatting Building Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = DataFrameCleaner(path=r'D:\\OneDrive - Swinburne University\\Comp Sci\\2024 Semester 1\\Group Project\\Data\\exploratory_data\\b1', building_no=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = DataFrameCleaner(path=r'D:\\OneDrive - Swinburne University\\Comp Sci\\2024 Semester 1\\Group Project\\Data\\exploratory_data\\b2', building_no=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = DataFrameCleaner(path=r'D:\\OneDrive - Swinburne University\\Comp Sci\\2024 Semester 1\\Group Project\\Data\\exploratory_data\\b3', building_no=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validated Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building 1 validations started\n",
      "C02 Validations skipped\n",
      "Louver status validations skipped\n",
      "Building 1 validations complete\n"
     ]
    }
   ],
   "source": [
    "# Building 1\n",
    "df_valid1 = ValidationHandler(test1.df).df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building 2 validations started\n",
      "Fan Validation skipped: check_fan_on_occupied_c02\n",
      "Damper status validations skipped\n",
      "Louver status validations skipped\n",
      "Building 2 validations complete\n"
     ]
    }
   ],
   "source": [
    "# Building 2\n",
    "df_valid2 = ValidationHandler(test2.df).df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building 3 validations started\n"
     ]
    }
   ],
   "source": [
    "# Building 3\n",
    "df_valid3 = ValidationHandler(test3.df).df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, df in enumerate([df_valid1, df_valid2, df_valid3]):\n",
    "#     df.to_parquet(os.path.join(r'D:\\OneDrive - Swinburne University\\Comp Sci\\2024 Semester 1\\Group Project\\Data\\validated_data', f'building{i+1}.parquet'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.df['Faulty'] = True\n",
    "test1.df.loc[df_valid1.index, 'Faulty'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2.df['Faulty'] = True\n",
    "test2.df.loc[df_valid2.index, 'Faulty'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3.df['Faulty'] = True\n",
    "test3.df.loc[df_valid3.index, 'Faulty'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate([test1.df, test2.df, test3.df]):\n",
    "    df.to_parquet(os.path.join(r'D:\\OneDrive - Swinburne University\\Comp Sci\\2024 Semester 1\\Group Project\\Data\\cleaned_data', f'cleaned{i+1}.parquet'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fan Status Value Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Fan_status\n",
       "On     779635\n",
       "Off    278873\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Zone_name  Fan_status\n",
       "Acu101     On            34462\n",
       "           Off           13652\n",
       "Acu102     On            34462\n",
       "           Off           13652\n",
       "Acu103     On            34462\n",
       "           Off           13652\n",
       "Acu104     On            33964\n",
       "           Off           14150\n",
       "Acu105     On            33902\n",
       "           Off           14212\n",
       "Acu106     On            33899\n",
       "           Off           14215\n",
       "Acu107     On            42058\n",
       "           Off            6056\n",
       "Acu201     On            35664\n",
       "           Off           12450\n",
       "Acu202     On            35314\n",
       "           Off           12800\n",
       "Acu203     On            35664\n",
       "           Off           12450\n",
       "Acu204     On            35664\n",
       "           Off           12450\n",
       "Acu205     On            35664\n",
       "           Off           12450\n",
       "Acu206     On            35664\n",
       "           Off           12450\n",
       "Acu207     On            35664\n",
       "           Off           12450\n",
       "Acu301     On            35391\n",
       "           Off           12723\n",
       "Acu302     On            35391\n",
       "           Off           12723\n",
       "Acu303     On            35391\n",
       "           Off           12723\n",
       "Acu304     On            35391\n",
       "           Off           12723\n",
       "Acu305     On            35391\n",
       "           Off           12723\n",
       "Acu306     On            35391\n",
       "           Off           12723\n",
       "Acu307     On            35391\n",
       "           Off           12723\n",
       "Acu308     On            35391\n",
       "           Off           12723\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Fan_status\n",
       "Off    119852\n",
       "On      17938\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Zone_name  Fan_status\n",
       "Ac-2-1     Off           22502\n",
       "           On             5056\n",
       "Ac-2-2     Off           27190\n",
       "           On              368\n",
       "Ac-2-3     Off           26071\n",
       "           On             1487\n",
       "Ac-2-4     Off           21422\n",
       "           On             6136\n",
       "Ac-2-5     Off           22667\n",
       "           On             4891\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Fan_status\n",
       "Off    467525\n",
       "On     152400\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Zone_name  Fan_status\n",
       "G-01       Off           38710\n",
       "           On             2618\n",
       "G-02       Off           36099\n",
       "           On             5230\n",
       "G-03       Off           31462\n",
       "           On             9866\n",
       "G-04       Off           34749\n",
       "           On             6579\n",
       "G-05       Off           38296\n",
       "           On             3033\n",
       "G-06       Off           31039\n",
       "           On            10289\n",
       "G-07       Off           32738\n",
       "           On             8590\n",
       "G-08       Off           30790\n",
       "           On            10538\n",
       "L1-01      On            22637\n",
       "           Off           18691\n",
       "L1-02      Off           32750\n",
       "           On             8579\n",
       "L1-03      On            41329\n",
       "L1-04      Off           26572\n",
       "           On            14757\n",
       "L1-05      Off           32979\n",
       "           On             8349\n",
       "L1-06      Off           41328\n",
       "L1-07      Off           41322\n",
       "           On                6\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Building 1')\n",
    "display(df_valid1.Fan_status.value_counts(dropna=False))\n",
    "display(df_valid1.groupby('Zone_name').Fan_status.value_counts())\n",
    "\n",
    "print('Building 2')\n",
    "display(df_valid2.Fan_status.value_counts(dropna=False))\n",
    "display(df_valid2.groupby('Zone_name').Fan_status.value_counts())\n",
    "\n",
    "print('Building 3')\n",
    "display(df_valid3.Fan_status.value_counts(dropna=False))\n",
    "display(df_valid3.groupby('Zone_name').Fan_status.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
